{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis POC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook is a scratch pad, for sentiment analysis POC. \n",
    "* The idea is to try out few pre-trained sentiment analysis models and see which one works for our use case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in d:\\workspace\\aletheia\\env\\lib\\site-packages (4.21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\workspace\\aletheia\\env\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in d:\\workspace\\aletheia\\env\\lib\\site-packages (from transformers) (0.11.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\workspace\\aletheia\\env\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in d:\\workspace\\aletheia\\env\\lib\\site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: requests in d:\\workspace\\aletheia\\env\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\workspace\\aletheia\\env\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\workspace\\aletheia\\env\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\workspace\\aletheia\\env\\lib\\site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in d:\\workspace\\aletheia\\env\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\workspace\\aletheia\\env\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\workspace\\aletheia\\env\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in d:\\workspace\\aletheia\\env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\workspace\\aletheia\\env\\lib\\site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\workspace\\aletheia\\env\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\workspace\\aletheia\\env\\lib\\site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\workspace\\aletheia\\env\\lib\\site-packages (from requests->transformers) (3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# # ## installing required libraries\n",
    "# ! pip install beautifulsoup4\n",
    "# ! pip install pandas\n",
    "# ! pip install numpy\n",
    "# ! pip install plotly\n",
    "# ! pip install nbformat\n",
    "# ! pip install ipykernel\n",
    "# ! pip install matplotlip\n",
    "# ! pip install wordcloud\n",
    "# ! pip install gensim\n",
    "# ! pip install pyLDAvis\n",
    "# ! pip install nltk\n",
    "# ! pip install -U pip setuptools wheel\n",
    "# ! pip install -U spacy\n",
    "# ! python -m spacy download en_core_web_trf \n",
    "# ! python -m spacy download en_core_web_md\n",
    "# ! pip install joblib\n",
    "# ! pip install tqdm\n",
    "# ! pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gaura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "d:\\workspace\\Aletheia\\env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\workspace\\Aletheia\\env\\lib\\site-packages\\past\\builtins\\misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gaura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gaura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gaura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## lets load \n",
    "import pandas as pd\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)\n",
    "\n",
    "import re\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "from pprint import pprint\n",
    "\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as io\n",
    "\n",
    "# loading library\n",
    "import pickle\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../utils'))\n",
    "\n",
    "## importing custom modules\n",
    "import common_utils\n",
    "import gensim_utils\n",
    "import sklearn_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3972, 12)\n"
     ]
    }
   ],
   "source": [
    "## reading manaully scrapped data\n",
    "data = pd.read_csv('../data/scrapped_fox_data_clean.csv')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████| 3972/3972 [00:01<00:00, 2542.73it/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "     text = common_utils.clean_html(text)\n",
    "     text = common_utils.lower_case(text)\n",
    "     text = common_utils.remove_line_breaks(text)\n",
    "     text = common_utils.remove_punctuation(text)\n",
    "     text = common_utils.remove_numbers(text)\n",
    "     text = common_utils.remove_extra_spaces(text)\n",
    "     # text = remove_stopwords(text)\n",
    "     return text\n",
    "\n",
    "data[\"clean_text\"] = data[\"text\"].progress_apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    former governor and first term democratic sen ...\n",
       "1    president biden urged democrats on wednesday t...\n",
       "2    the famous naked cowboy in new york citys time...\n",
       "3    liberal groups in wisconsin seeking to change ...\n",
       "4    texas gubernatorial nominee beto o’rourke is a...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()[\"clean_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Using VADER\n",
    "(Valence Aware Dictionary and sEntiment Reasoner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes\n",
    "* Uses Bag of words approach\n",
    "* Gives +tive, -tive or neutral values to each of the words in the sentence and then gives combined value of that to tell us whether the sentence is positive, negative or neutral\n",
    "* Does not account for relationship between words :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Former governor and first term Democratic Sen. Maggie Hassan of New Hampshire and Republican challenger Don Bolduc took aim at each other over inflation, abortion, national security, the border crisis, election denialism, and many more issues in their third and final debate in their crucial battleground state race that’s among a handful across the country that will likely determine if the GOP wins back the Senate majority. But ahead of the verbal crossfire on the debate stage, Bolduc – a former Army general who served ten tours of duty in the war in Afghanistan – was allegedly assaulted as he arrived at the debate site at Saint Anselm College’s New Hampshire Institute of Politics on Wednesday evening. According to the Bolduc campaign, a bystander standing in the crowd outside the debate site took a swing at the former general as he arrived. The campaign says Bolduc was slightly grazed but not injured.&nbsp; Rick Wiley of the Bolduc campaign tells Fox News the person who threw the punch at the former general appeared to be a Libertarian activist. THE FINAL COUNTDOWN: WHAT\\'S AT STAKE IN THE MIDTERM ELECTIONS  Hassan\\'s campaign communications director Kevin Donohoe tweeted about the incident, writing: \"Disgusting behavior. We saw this same libertarian party activist get aggressive with our campaign volunteers at this debate and the last.\" Bolduc referenced the altercation near the end of the debate, when he and Hassan discussed the brutal attack on House Speaker Nancy Pelosi’s husband at their San Francisco home. The GOP Senate nominee said \"it\\'s a sign of political problems. Republicans and Democrat, that fuel issues with people that get them to the point where they are just so upset at an individual that they strike out at them. Happened to me outside just before I came in. Right. This is wrong and it needs to be stopped.\" Bolduc campaign spokesperson Kate Constantini told Fox News in a statement that \"as the General said on stage tonight, it’s time to lower the temperature of the political discourse in this country. Prior to the debate, an individual in the crowd gathered outside attempted to punch the General and was quickly apprehended and arrested. We are grateful to the quick response from law enforcement on the scene.\" CHECK OUT THE LATEST FOX NEWS MIDTERMS POWER RANKINGS The former general, who’s making his second straight bid for the Senate in New Hampshire, has run a populist-style campaign this cycle, emphasizing his MAGA-Republican and outsider credentials in a crowded and combustible GOP primary. In mid-September, Bolduc narrowly edged more mainstream conservative Chuck Morse, the state Senate president who was backed by popular GOP Gov. Chris Sununu, to win the nomination. And over the past six weeks Bolduc has slowly but steadily eaten into Hassan’s once upper-single digit lead in public opinion polling. The most recent surveys in the race suggest it’s a margin of error contest with six days to go until the election.  The two candidates traded fire at the top of the debate over the combustible issue of abortion. For weeks Hassan’s campaign and allied Democratic groups have showcased clips of Bolduc from last year vowing that he would never \"vote contrary to pro-life\" and from June celebrating the blockbuster move by the Supreme Court’s conservative majority to overturn the landmark Roe v. Wade ruling, sending the issue of legalized abortion back to the states. HASSAN TOUTS EFFORTS TO PUSH BIDEN TO DO MORE TO LOWER PRICES But Buldoc told Fox News immediately after capturing the GOP nomination that if he were in the Senate, he would not support a proposal, unveiled earlier this month by Republican Sen. Lindsey Graham of South Carolina, to implement a 15-week federal abortion ban, because abortion is now a state issue. Bolduc, at Wednesday’s debate, reiterated that \"I have promised to all Granite Staters that I will not vote for any federal legislation that has to do with abortion. It is a state’s rights issue.\" Hassan emphasized that \"this is about a fundamental right of a woman to make her own health care decisions and her health and safety, and I believe strongly that those decisions need to be made by a woman and her doctor.\"  And the senator charged that Bolduc \"is a yes vote for a nationwide abortion ban and he’s trying to conceal his record.\" \"That is an absolute lie,\" the GOP challenger fired back, before alleging that Hassan \"does believe in abortion up to birth.\" The senator retorted that \"he’s really working to conceal his extremism from Granite Staters.\" On inflation, Hassan touted that \"I have stood up to big pharma and passed legislation that will lower people’s prescription drug costs. My opponent says he wouldn’t have done that. I have proposed suspending the gas tax until we see a great reduction in gas prices. My opponent stands with big oil and says he wouldn’t do that either.\" She also showcased her support for bipartisan spending bills she helped pass during both the Trump and Biden administration. FORMER ARMY GENERAL TURNED GOP SENATE NOMINEE IN KEY BATTLEGROUND HIGHLIGHTS ‘NEW MISSION’ Bolduc stressed that \"I wouldn’t have voted for them. They were unnecessary.\" And pointing to record inflation, he charged that \"all her votes in the Senate have caused this heating and eating issue that we have. Retirees going back to work. She’s created it by her 100% support to Joe Biden’s failed policies… She’s caused these problems for many Granite Staters going into the winter not knowing how they’ll feed their children and heat their homes.\"  Hassan, responding, claimed Bolduc is in big oil’s pockets, saying \"you’re hearing Don Bolduc sing big oil’s song.\" Bolduc, who said during the primary campaign that he supported former President Donald Trump’s repeated unproven claims that his 2020 election loss to Biden was due to \"massive voter fraud,\" quickly reversed course after his nomination victory. In a Fox News interview days later, Bolduc said that after speaking with Granite Staters, he had \"come to the conclusion\" that the 2020 presidential election \"was not stolen.\" TULSI GABBARD TEAMS UP WITH DON BOLDUC ON THE CAMPAIGN TRAIL Trump, who stayed neutral in the Republican primary in New Hampshire, on Monday endorsed Bolduc but dinged him over reversing his views on the 2020 election.&nbsp; \"General Don Bolduc has run a great campaign to be the U.S. Senator from the beautiful State of New Hampshire. He was a strong and proud ‘Election Denier,’ a big reason that he won the Nomination, but he then disavowed,\" Trump wrote on social media. \"He has since come back, at least on busing, but that is only a small part of N.H. Election Fraud. Nevertheless, Don Bolduc has asked for my Endorsement, and he’s got it, Complete &amp; Total,\" the former president added. At the debate, Hassan argued that Bolduc’s changing responses on whether the 2020 election was stolen show that he’s \"an extremist, the most extreme nominee for U.S. Senate New Hampshire has seen in modern history and he keeps trying to conceal that from Granite Staters.\"&nbsp; And she argued that \"he spent over a year in New Hampshire stoking the big lie… he then has begun to cast doubt on the 2022 elections, saying there will be ballot dumps in the middle of the night.\" CLICK HERE TO GET THE FOX NEWS APP Given the chance to respond to Hassan’s attacks, Bolduc criticized the debate’s moderators, saying \"thanks for giving her a softball, because that’s exactly what she needed because she can’t hit a fastball.\"&nbsp; And he stressed that \"the bottom line is we need to focus on the future.\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = data[\"text\"][0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.105, 'neu': 0.812, 'pos': 0.083, 'compound': -0.9869}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hassan and Bolduc trade fire in final showdown after GOP nominee comes under attack arriving at debate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.268, 'neu': 0.732, 'pos': 0.0, 'compound': -0.6705}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## running the sentiment analysis on entire dataset\n",
    "print(data[\"title\"][0])\n",
    "sia.polarity_scores(data[\"title\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets rename index to id\n",
    "data.rename(columns={\"index\":\"id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3972/3972 [00:00<00:00, 5999.72it/s]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for idx, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    text = row[\"title\"]\n",
    "    id = idx\n",
    "    results[id] = sia.polarity_scores(text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(results, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>last_published_date</th>\n",
       "      <th>authors</th>\n",
       "      <th>text</th>\n",
       "      <th>published_day</th>\n",
       "      <th>published_month</th>\n",
       "      <th>num_authors</th>\n",
       "      <th>author</th>\n",
       "      <th>word_count</th>\n",
       "      <th>line_count</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hassan and Bolduc trade fire in final showdown...</td>\n",
       "      <td>A bystander took a swing at Republican Senate ...</td>\n",
       "      <td>https://www.foxnews.com/politics/hassan-bolduc...</td>\n",
       "      <td>2022-11-02 22:47:00-04:00</td>\n",
       "      <td>[{'name': 'Paul Steinhauser'}]</td>\n",
       "      <td>Former governor and first term Democratic Sen....</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Paul_Steinhauser</td>\n",
       "      <td>1271</td>\n",
       "      <td>62</td>\n",
       "      <td>former governor and first term democratic sen ...</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biden suggests voting for Republicans is a thr...</td>\n",
       "      <td>President Biden said the only way to repudiate...</td>\n",
       "      <td>https://www.foxnews.com/politics/biden-speech</td>\n",
       "      <td>2022-11-02 22:15:46-04:00</td>\n",
       "      <td>[{'name': 'Haris Alic'}]</td>\n",
       "      <td>President Biden urged Democrats on Wednesday t...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Haris_Alic</td>\n",
       "      <td>478</td>\n",
       "      <td>22</td>\n",
       "      <td>president biden urged democrats on wednesday t...</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NYC's Naked Cowboy makes endorsement for gov w...</td>\n",
       "      <td>New York City's Naked Cowboy endorsed Lee Zeld...</td>\n",
       "      <td>https://www.foxnews.com/politics/nyc-naked-cow...</td>\n",
       "      <td>2022-11-02 21:58:25-04:00</td>\n",
       "      <td>[{'name': 'Adam Sabes'}]</td>\n",
       "      <td>The famous Naked Cowboy in New York City's Tim...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Adam_Sabes</td>\n",
       "      <td>205</td>\n",
       "      <td>18</td>\n",
       "      <td>the famous naked cowboy in new york citys time...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wisconsin courts shoot down liberal groups' at...</td>\n",
       "      <td>A Wisconsin appeals court and a circuit judge ...</td>\n",
       "      <td>https://www.foxnews.com/politics/wisconsin-cou...</td>\n",
       "      <td>2022-11-02 21:44:40-04:00</td>\n",
       "      <td>[{'name': 'Bradford Betz'}]</td>\n",
       "      <td>Liberal groups in Wisconsin seeking to change ...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Bradford_Betz</td>\n",
       "      <td>381</td>\n",
       "      <td>20</td>\n",
       "      <td>liberal groups in wisconsin seeking to change ...</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Texas gubernatorial candidate Beto O'Rourke jo...</td>\n",
       "      <td>Texas gubernatorial nominee Beto O’Rourke is t...</td>\n",
       "      <td>https://www.foxnews.com/politics/texas-guberna...</td>\n",
       "      <td>2022-11-02 20:38:30-04:00</td>\n",
       "      <td>[{'name': 'Bradford Betz'}]</td>\n",
       "      <td>Texas gubernatorial nominee Beto O’Rourke is a...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Bradford_Betz</td>\n",
       "      <td>267</td>\n",
       "      <td>15</td>\n",
       "      <td>texas gubernatorial nominee beto o’rourke is a...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Hassan and Bolduc trade fire in final showdown...   \n",
       "1  Biden suggests voting for Republicans is a thr...   \n",
       "2  NYC's Naked Cowboy makes endorsement for gov w...   \n",
       "3  Wisconsin courts shoot down liberal groups' at...   \n",
       "4  Texas gubernatorial candidate Beto O'Rourke jo...   \n",
       "\n",
       "                                         description  \\\n",
       "0  A bystander took a swing at Republican Senate ...   \n",
       "1  President Biden said the only way to repudiate...   \n",
       "2  New York City's Naked Cowboy endorsed Lee Zeld...   \n",
       "3  A Wisconsin appeals court and a circuit judge ...   \n",
       "4  Texas gubernatorial nominee Beto O’Rourke is t...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.foxnews.com/politics/hassan-bolduc...   \n",
       "1      https://www.foxnews.com/politics/biden-speech   \n",
       "2  https://www.foxnews.com/politics/nyc-naked-cow...   \n",
       "3  https://www.foxnews.com/politics/wisconsin-cou...   \n",
       "4  https://www.foxnews.com/politics/texas-guberna...   \n",
       "\n",
       "         last_published_date                         authors  \\\n",
       "0  2022-11-02 22:47:00-04:00  [{'name': 'Paul Steinhauser'}]   \n",
       "1  2022-11-02 22:15:46-04:00        [{'name': 'Haris Alic'}]   \n",
       "2  2022-11-02 21:58:25-04:00        [{'name': 'Adam Sabes'}]   \n",
       "3  2022-11-02 21:44:40-04:00     [{'name': 'Bradford Betz'}]   \n",
       "4  2022-11-02 20:38:30-04:00     [{'name': 'Bradford Betz'}]   \n",
       "\n",
       "                                                text  published_day  \\\n",
       "0  Former governor and first term Democratic Sen....              2   \n",
       "1  President Biden urged Democrats on Wednesday t...              2   \n",
       "2  The famous Naked Cowboy in New York City's Tim...              2   \n",
       "3  Liberal groups in Wisconsin seeking to change ...              2   \n",
       "4  Texas gubernatorial nominee Beto O’Rourke is a...              2   \n",
       "\n",
       "   published_month  num_authors            author  word_count  line_count  \\\n",
       "0               11            1  Paul_Steinhauser        1271          62   \n",
       "1               11            1        Haris_Alic         478          22   \n",
       "2               11            1        Adam_Sabes         205          18   \n",
       "3               11            1     Bradford_Betz         381          20   \n",
       "4               11            1     Bradford_Betz         267          15   \n",
       "\n",
       "                                          clean_text    neg    neu    pos  \\\n",
       "0  former governor and first term democratic sen ...  0.268  0.732  0.000   \n",
       "1  president biden urged democrats on wednesday t...  0.298  0.702  0.000   \n",
       "2  the famous naked cowboy in new york citys time...  0.000  0.757  0.243   \n",
       "3  liberal groups in wisconsin seeking to change ...  0.290  0.710  0.000   \n",
       "4  texas gubernatorial nominee beto o’rourke is a...  0.000  1.000  0.000   \n",
       "\n",
       "   compound  \n",
       "0   -0.6705  \n",
       "1   -0.5267  \n",
       "2    0.5423  \n",
       "3   -0.5423  \n",
       "4    0.0000  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat([data, results_df], axis=1)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Former President Trump celebrates 'ALL' endorsement wins in primary: 'Great candidates!'\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.loc[combined_df[\"pos\"].idxmax(), \"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published_day</th>\n",
       "      <th>published_month</th>\n",
       "      <th>num_authors</th>\n",
       "      <th>word_count</th>\n",
       "      <th>line_count</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3972.000000</td>\n",
       "      <td>3972.000000</td>\n",
       "      <td>3972.000000</td>\n",
       "      <td>3972.000000</td>\n",
       "      <td>3972.000000</td>\n",
       "      <td>3972.000000</td>\n",
       "      <td>3972.000000</td>\n",
       "      <td>3972.000000</td>\n",
       "      <td>3972.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.787513</td>\n",
       "      <td>8.453424</td>\n",
       "      <td>1.119084</td>\n",
       "      <td>610.804884</td>\n",
       "      <td>31.652064</td>\n",
       "      <td>0.109221</td>\n",
       "      <td>0.812165</td>\n",
       "      <td>0.078617</td>\n",
       "      <td>-0.065043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.934083</td>\n",
       "      <td>1.335676</td>\n",
       "      <td>0.447909</td>\n",
       "      <td>340.785100</td>\n",
       "      <td>19.232276</td>\n",
       "      <td>0.136235</td>\n",
       "      <td>0.158318</td>\n",
       "      <td>0.110806</td>\n",
       "      <td>0.394567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.966100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.701000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.361200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.823000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>734.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.194000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.177900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9672.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>0.837000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.936000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       published_day  published_month  num_authors   word_count   line_count  \\\n",
       "count    3972.000000      3972.000000  3972.000000  3972.000000  3972.000000   \n",
       "mean       16.787513         8.453424     1.119084   610.804884    31.652064   \n",
       "std         8.934083         1.335676     0.447909   340.785100    19.232276   \n",
       "min         1.000000         6.000000     0.000000    31.000000     3.000000   \n",
       "25%         9.000000         7.000000     1.000000   399.000000    21.000000   \n",
       "50%        18.000000         8.000000     1.000000   534.000000    28.000000   \n",
       "75%        25.000000        10.000000     1.000000   734.000000    37.000000   \n",
       "max        31.000000        11.000000     5.000000  9672.000000   647.000000   \n",
       "\n",
       "               neg          neu          pos     compound  \n",
       "count  3972.000000  3972.000000  3972.000000  3972.000000  \n",
       "mean      0.109221     0.812165     0.078617    -0.065043  \n",
       "std       0.136235     0.158318     0.110806     0.394567  \n",
       "min       0.000000     0.163000     0.000000    -0.966100  \n",
       "25%       0.000000     0.701000     0.000000    -0.361200  \n",
       "50%       0.000000     0.823000     0.000000     0.000000  \n",
       "75%       0.194000     1.000000     0.155000     0.177900  \n",
       "max       0.837000     1.000000     0.668000     0.936000  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "## pulling a specific model pretrained on sentiment analysis\n",
    "task='sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biden suggests voting for Republicans is a threat to democracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.298, 'neu': 0.702, 'pos': 0.0, 'compound': -0.5267}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data[\"title\"][1])\n",
    "sia.polarity_scores(data[\"title\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roberta_neg': 0.66241485,\n",
       " 'roberta_neu': 0.3247515,\n",
       " 'roberta_pos': 0.012833751}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## running on roberta model\n",
    "def get_roberta_sentiment(text):\n",
    "    encoded_text = tokenizer(text, return_tensors=\"pt\")\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    ## scores are in order of negative, neutral and positive\n",
    "    scores_dict = {\"roberta_neg\":scores[0], \"roberta_neu\":scores[1], \"roberta_pos\":scores[2]}\n",
    "    return scores_dict\n",
    "\n",
    "\n",
    "scores = get_roberta_sentiment(data[\"title\"][1])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3972 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 0\n",
      "Broke for id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/3972 [00:02<37:46,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/3972 [00:03<09:30,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 8\n",
      "Broke for id 9\n",
      "Broke for id 10\n",
      "Broke for id 11\n",
      "Broke for id 12\n",
      "Broke for id 13\n",
      "Broke for id 14\n",
      "Broke for id 15\n",
      "Broke for id 16\n",
      "Broke for id 17\n",
      "Broke for id 18\n",
      "Broke for id 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/3972 [00:04<08:37,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 21\n",
      "Broke for id 22\n",
      "Broke for id 23\n",
      "Broke for id 24\n",
      "Broke for id 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 27/3972 [00:04<08:45,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 29/3972 [00:05<11:24,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 29\n",
      "Broke for id 30\n",
      "Broke for id 31\n",
      "Broke for id 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 34/3972 [00:06<11:18,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 34\n",
      "Broke for id 35\n",
      "Broke for id 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 40/3972 [00:08<19:23,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 42/3972 [00:09<19:28,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 44/3972 [00:10<19:26,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 44\n",
      "Broke for id 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 48/3972 [00:11<22:24,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 48\n",
      "Broke for id 49\n",
      "Broke for id 50\n",
      "Broke for id 51\n",
      "Broke for id 52\n",
      "Broke for id 53\n",
      "Broke for id 54\n",
      "Broke for id 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 57/3972 [00:12<12:24,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 57\n",
      "Broke for id 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 60/3972 [00:13<14:18,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 60\n",
      "Broke for id 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 63/3972 [00:14<15:22,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 65/3972 [00:14<15:05,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 69/3972 [00:16<20:55,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 69\n",
      "Broke for id 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 72/3972 [00:17<20:31,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 72\n",
      "Broke for id 73\n",
      "Broke for id 74\n",
      "Broke for id 75\n",
      "Broke for id 76\n",
      "Broke for id 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 80/3972 [00:19<18:06,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 82/3972 [00:20<19:58,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 82\n",
      "Broke for id 83\n",
      "Broke for id 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 86/3972 [00:20<15:43,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 86\n",
      "Broke for id 87\n",
      "Broke for id 88\n",
      "Broke for id 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 91/3972 [00:21<12:18,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 93/3972 [00:21<14:57,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 95/3972 [00:22<15:39,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 95\n",
      "Broke for id 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 98/3972 [00:23<16:53,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broke for id 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 99/3972 [00:24<15:39,  4.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [109], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m vader_results\u001b[39m.\u001b[39mitems():\n\u001b[0;32m      9\u001b[0m     vader_results_rename[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvader_\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m v\n\u001b[1;32m---> 10\u001b[0m roberta_results \u001b[39m=\u001b[39m get_roberta_sentiment(text)\n\u001b[0;32m     11\u001b[0m both \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mvader_results_rename, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mroberta_results}\n\u001b[0;32m     12\u001b[0m results[idx] \u001b[39m=\u001b[39m both\n",
      "Cell \u001b[1;32mIn [93], line 4\u001b[0m, in \u001b[0;36mget_roberta_sentiment\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_roberta_sentiment\u001b[39m(text):\n\u001b[0;32m      3\u001b[0m     encoded_text \u001b[39m=\u001b[39m tokenizer(text, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     output \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mencoded_text)\n\u001b[0;32m      5\u001b[0m     scores \u001b[39m=\u001b[39m output[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m      6\u001b[0m     scores \u001b[39m=\u001b[39m softmax(scores)\n",
      "File \u001b[1;32md:\\workspace\\Aletheia\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\workspace\\Aletheia\\env\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1206\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1200\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1204\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1206\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroberta(\n\u001b[0;32m   1207\u001b[0m     input_ids,\n\u001b[0;32m   1208\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1209\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1210\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1211\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1212\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1213\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1214\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1215\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1216\u001b[0m )\n\u001b[0;32m   1217\u001b[0m sequence_output \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1218\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32md:\\workspace\\Aletheia\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\workspace\\Aletheia\\env\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:848\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    839\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    841\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m    842\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m    843\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    846\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    847\u001b[0m )\n\u001b[1;32m--> 848\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m    849\u001b[0m     embedding_output,\n\u001b[0;32m    850\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m    851\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    852\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m    853\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m    854\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m    855\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    856\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    857\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    858\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    859\u001b[0m )\n\u001b[0;32m    860\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    861\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\workspace\\Aletheia\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\workspace\\Aletheia\\env\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:524\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    515\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    516\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    517\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    521\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    522\u001b[0m     )\n\u001b[0;32m    523\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 524\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    525\u001b[0m         hidden_states,\n\u001b[0;32m    526\u001b[0m         attention_mask,\n\u001b[0;32m    527\u001b[0m         layer_head_mask,\n\u001b[0;32m    528\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    529\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    530\u001b[0m         past_key_value,\n\u001b[0;32m    531\u001b[0m         output_attentions,\n\u001b[0;32m    532\u001b[0m     )\n\u001b[0;32m    534\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    535\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32md:\\workspace\\Aletheia\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\workspace\\Aletheia\\env\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:451\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    448\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    449\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 451\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    452\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[0;32m    453\u001b[0m )\n\u001b[0;32m    454\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[0;32m    456\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32md:\\workspace\\Aletheia\\env\\lib\\site-packages\\transformers\\pytorch_utils.py:243\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 243\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[1;32md:\\workspace\\Aletheia\\env\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:464\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[0;32m    463\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 464\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(intermediate_output, attention_output)\n\u001b[0;32m    465\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32md:\\workspace\\Aletheia\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\workspace\\Aletheia\\env\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:375\u001b[0m, in \u001b[0;36mRobertaOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor, input_tensor: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m--> 375\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense(hidden_states)\n\u001b[0;32m    376\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    377\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(hidden_states \u001b[39m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32md:\\workspace\\Aletheia\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\workspace\\Aletheia\\env\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for idx, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    try:\n",
    "        text = row[\"text\"]\n",
    "        id = idx\n",
    "        vader_results = sia.polarity_scores(text)\n",
    "        vader_results_rename = {}\n",
    "        for k,v in vader_results.items():\n",
    "            vader_results_rename[f\"vader_{k}\"] = v\n",
    "        roberta_results = get_roberta_sentiment(text)\n",
    "        both = {**vader_results_rename, **roberta_results}\n",
    "        results[idx] = both\n",
    "    except RuntimeError:\n",
    "        print(f\"Broke for id {idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>roberta_neg</th>\n",
       "      <th>roberta_neu</th>\n",
       "      <th>roberta_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.268</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6705</td>\n",
       "      <td>0.214919</td>\n",
       "      <td>0.765167</td>\n",
       "      <td>0.019915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.298</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5267</td>\n",
       "      <td>0.662415</td>\n",
       "      <td>0.324751</td>\n",
       "      <td>0.012834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.005948</td>\n",
       "      <td>0.538470</td>\n",
       "      <td>0.455582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.290</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>0.346270</td>\n",
       "      <td>0.637059</td>\n",
       "      <td>0.016671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.056946</td>\n",
       "      <td>0.885563</td>\n",
       "      <td>0.057491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3967</th>\n",
       "      <td>0.152</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.224884</td>\n",
       "      <td>0.703206</td>\n",
       "      <td>0.071910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3968</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.570033</td>\n",
       "      <td>0.403358</td>\n",
       "      <td>0.026609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3969</th>\n",
       "      <td>0.080</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.502582</td>\n",
       "      <td>0.481971</td>\n",
       "      <td>0.015446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>0.173</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>0.048049</td>\n",
       "      <td>0.920026</td>\n",
       "      <td>0.031925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.006440</td>\n",
       "      <td>0.189757</td>\n",
       "      <td>0.803802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3972 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      vader_neg  vader_neu  vader_pos  vader_compound  roberta_neg  \\\n",
       "0         0.268      0.732      0.000         -0.6705     0.214919   \n",
       "1         0.298      0.702      0.000         -0.5267     0.662415   \n",
       "2         0.000      0.757      0.243          0.5423     0.005948   \n",
       "3         0.290      0.710      0.000         -0.5423     0.346270   \n",
       "4         0.000      1.000      0.000          0.0000     0.056946   \n",
       "...         ...        ...        ...             ...          ...   \n",
       "3967      0.152      0.691      0.157          0.0258     0.224884   \n",
       "3968      0.000      1.000      0.000          0.0000     0.570033   \n",
       "3969      0.080      0.747      0.172          0.3818     0.502582   \n",
       "3970      0.173      0.827      0.000         -0.3182     0.048049   \n",
       "3971      0.000      0.763      0.237          0.4767     0.006440   \n",
       "\n",
       "      roberta_neu  roberta_pos  \n",
       "0        0.765167     0.019915  \n",
       "1        0.324751     0.012834  \n",
       "2        0.538470     0.455582  \n",
       "3        0.637059     0.016671  \n",
       "4        0.885563     0.057491  \n",
       "...           ...          ...  \n",
       "3967     0.703206     0.071910  \n",
       "3968     0.403358     0.026609  \n",
       "3969     0.481971     0.015446  \n",
       "3970     0.920026     0.031925  \n",
       "3971     0.189757     0.803802  \n",
       "\n",
       "[3972 rows x 7 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([data, results_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Crist praises Biden, says president is 'phenomenal' and he 'can't wait' to have his support in Florida\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.loc[final_df[\"roberta_pos\"].idxmax(), \"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Former President Trump celebrates 'ALL' endorsement wins in primary: 'Great candidates!'\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.loc[final_df[\"vader_pos\"].idxmax(), \"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "914eef65da1375b54976b1eb4c0a6192cf68c9b736369c9231d1c03e2f3fef86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
