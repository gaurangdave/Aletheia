{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alternative text](../images/alatheia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis POC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook is a scratch pad, for sentiment analysis POC. \n",
    "* The idea is to try out few pre-trained sentiment analysis models and see which one works for our use case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\workspace\\aletheia\\env\\lib\\site-packages (1.13.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\workspace\\aletheia\\env\\lib\\site-packages (from torch) (4.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# # ## installing required libraries\n",
    "# ! pip install beautifulsoup4\n",
    "# ! pip install pandas\n",
    "# ! pip install numpy\n",
    "# ! pip install plotly\n",
    "# ! pip install nbformat\n",
    "# ! pip install ipykernel\n",
    "# ! pip install matplotlip\n",
    "# ! pip install wordcloud\n",
    "# ! pip install gensim\n",
    "# ! pip install pyLDAvis\n",
    "# ! pip install nltk\n",
    "# ! pip install -U pip setuptools wheel\n",
    "# ! pip install -U spacy\n",
    "# ! python -m spacy download en_core_web_trf \n",
    "# ! python -m spacy download en_core_web_md\n",
    "# ! pip install joblib\n",
    "# ! pip install tqdm\n",
    "# ! pip install transformers\n",
    "! pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gaura\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## lets load \n",
    "import pandas as pd\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)\n",
    "\n",
    "import re\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "from pprint import pprint\n",
    "\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as io\n",
    "\n",
    "# loading library\n",
    "import pickle\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3972, 12)\n"
     ]
    }
   ],
   "source": [
    "## reading manaully scrapped data\n",
    "data = pd.read_csv('../data/scrapped_fox_data_clean.csv')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Using VADER\n",
    "(Valence Aware Dictionary and sEntiment Reasoner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes\n",
    "* Uses Bag of words approach\n",
    "* Gives +tive, -tive or neutral values to each of the words in the sentence and then gives combined value of that to tell us whether the sentence is positive, negative or neutral\n",
    "* Does not account for relationship between words :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Former governor and first term Democratic Sen. Maggie Hassan of New Hampshire and Republican challenger Don Bolduc took aim at each other over inflation, abortion, national security, the border crisis, election denialism, and many more issues in their third and final debate in their crucial battleground state race that’s among a handful across the country that will likely determine if the GOP wins back the Senate majority. But ahead of the verbal crossfire on the debate stage, Bolduc – a former Army general who served ten tours of duty in the war in Afghanistan – was allegedly assaulted as he arrived at the debate site at Saint Anselm College’s New Hampshire Institute of Politics on Wednesday evening. According to the Bolduc campaign, a bystander standing in the crowd outside the debate site took a swing at the former general as he arrived. The campaign says Bolduc was slightly grazed but not injured.&nbsp; Rick Wiley of the Bolduc campaign tells Fox News the person who threw the punch at the former general appeared to be a Libertarian activist. THE FINAL COUNTDOWN: WHAT\\'S AT STAKE IN THE MIDTERM ELECTIONS  Hassan\\'s campaign communications director Kevin Donohoe tweeted about the incident, writing: \"Disgusting behavior. We saw this same libertarian party activist get aggressive with our campaign volunteers at this debate and the last.\" Bolduc referenced the altercation near the end of the debate, when he and Hassan discussed the brutal attack on House Speaker Nancy Pelosi’s husband at their San Francisco home. The GOP Senate nominee said \"it\\'s a sign of political problems. Republicans and Democrat, that fuel issues with people that get them to the point where they are just so upset at an individual that they strike out at them. Happened to me outside just before I came in. Right. This is wrong and it needs to be stopped.\" Bolduc campaign spokesperson Kate Constantini told Fox News in a statement that \"as the General said on stage tonight, it’s time to lower the temperature of the political discourse in this country. Prior to the debate, an individual in the crowd gathered outside attempted to punch the General and was quickly apprehended and arrested. We are grateful to the quick response from law enforcement on the scene.\" CHECK OUT THE LATEST FOX NEWS MIDTERMS POWER RANKINGS The former general, who’s making his second straight bid for the Senate in New Hampshire, has run a populist-style campaign this cycle, emphasizing his MAGA-Republican and outsider credentials in a crowded and combustible GOP primary. In mid-September, Bolduc narrowly edged more mainstream conservative Chuck Morse, the state Senate president who was backed by popular GOP Gov. Chris Sununu, to win the nomination. And over the past six weeks Bolduc has slowly but steadily eaten into Hassan’s once upper-single digit lead in public opinion polling. The most recent surveys in the race suggest it’s a margin of error contest with six days to go until the election.  The two candidates traded fire at the top of the debate over the combustible issue of abortion. For weeks Hassan’s campaign and allied Democratic groups have showcased clips of Bolduc from last year vowing that he would never \"vote contrary to pro-life\" and from June celebrating the blockbuster move by the Supreme Court’s conservative majority to overturn the landmark Roe v. Wade ruling, sending the issue of legalized abortion back to the states. HASSAN TOUTS EFFORTS TO PUSH BIDEN TO DO MORE TO LOWER PRICES But Buldoc told Fox News immediately after capturing the GOP nomination that if he were in the Senate, he would not support a proposal, unveiled earlier this month by Republican Sen. Lindsey Graham of South Carolina, to implement a 15-week federal abortion ban, because abortion is now a state issue. Bolduc, at Wednesday’s debate, reiterated that \"I have promised to all Granite Staters that I will not vote for any federal legislation that has to do with abortion. It is a state’s rights issue.\" Hassan emphasized that \"this is about a fundamental right of a woman to make her own health care decisions and her health and safety, and I believe strongly that those decisions need to be made by a woman and her doctor.\"  And the senator charged that Bolduc \"is a yes vote for a nationwide abortion ban and he’s trying to conceal his record.\" \"That is an absolute lie,\" the GOP challenger fired back, before alleging that Hassan \"does believe in abortion up to birth.\" The senator retorted that \"he’s really working to conceal his extremism from Granite Staters.\" On inflation, Hassan touted that \"I have stood up to big pharma and passed legislation that will lower people’s prescription drug costs. My opponent says he wouldn’t have done that. I have proposed suspending the gas tax until we see a great reduction in gas prices. My opponent stands with big oil and says he wouldn’t do that either.\" She also showcased her support for bipartisan spending bills she helped pass during both the Trump and Biden administration. FORMER ARMY GENERAL TURNED GOP SENATE NOMINEE IN KEY BATTLEGROUND HIGHLIGHTS ‘NEW MISSION’ Bolduc stressed that \"I wouldn’t have voted for them. They were unnecessary.\" And pointing to record inflation, he charged that \"all her votes in the Senate have caused this heating and eating issue that we have. Retirees going back to work. She’s created it by her 100% support to Joe Biden’s failed policies… She’s caused these problems for many Granite Staters going into the winter not knowing how they’ll feed their children and heat their homes.\"  Hassan, responding, claimed Bolduc is in big oil’s pockets, saying \"you’re hearing Don Bolduc sing big oil’s song.\" Bolduc, who said during the primary campaign that he supported former President Donald Trump’s repeated unproven claims that his 2020 election loss to Biden was due to \"massive voter fraud,\" quickly reversed course after his nomination victory. In a Fox News interview days later, Bolduc said that after speaking with Granite Staters, he had \"come to the conclusion\" that the 2020 presidential election \"was not stolen.\" TULSI GABBARD TEAMS UP WITH DON BOLDUC ON THE CAMPAIGN TRAIL Trump, who stayed neutral in the Republican primary in New Hampshire, on Monday endorsed Bolduc but dinged him over reversing his views on the 2020 election.&nbsp; \"General Don Bolduc has run a great campaign to be the U.S. Senator from the beautiful State of New Hampshire. He was a strong and proud ‘Election Denier,’ a big reason that he won the Nomination, but he then disavowed,\" Trump wrote on social media. \"He has since come back, at least on busing, but that is only a small part of N.H. Election Fraud. Nevertheless, Don Bolduc has asked for my Endorsement, and he’s got it, Complete &amp; Total,\" the former president added. At the debate, Hassan argued that Bolduc’s changing responses on whether the 2020 election was stolen show that he’s \"an extremist, the most extreme nominee for U.S. Senate New Hampshire has seen in modern history and he keeps trying to conceal that from Granite Staters.\"&nbsp; And she argued that \"he spent over a year in New Hampshire stoking the big lie… he then has begun to cast doubt on the 2022 elections, saying there will be ballot dumps in the middle of the night.\" CLICK HERE TO GET THE FOX NEWS APP Given the chance to respond to Hassan’s attacks, Bolduc criticized the debate’s moderators, saying \"thanks for giving her a softball, because that’s exactly what she needed because she can’t hit a fastball.\"&nbsp; And he stressed that \"the bottom line is we need to focus on the future.\"'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = data[\"text\"][0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.105, 'neu': 0.812, 'pos': 0.083, 'compound': -0.9869}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hassan and Bolduc trade fire in final showdown after GOP nominee comes under attack arriving at debate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.268, 'neu': 0.732, 'pos': 0.0, 'compound': -0.6705}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## running the sentiment analysis on entire dataset\n",
    "print(data[\"title\"][0])\n",
    "sia.polarity_scores(data[\"title\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets rename index to id\n",
    "data.rename(columns={\"index\":\"id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3972/3972 [00:00<00:00, 5449.09it/s]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for idx, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    text = row[\"title\"]\n",
    "    id = idx\n",
    "    results[id] = sia.polarity_scores(text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(results, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>last_published_date</th>\n",
       "      <th>authors</th>\n",
       "      <th>text</th>\n",
       "      <th>published_day</th>\n",
       "      <th>published_month</th>\n",
       "      <th>num_authors</th>\n",
       "      <th>author</th>\n",
       "      <th>word_count</th>\n",
       "      <th>line_count</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hassan and Bolduc trade fire in final showdown...</td>\n",
       "      <td>A bystander took a swing at Republican Senate ...</td>\n",
       "      <td>https://www.foxnews.com/politics/hassan-bolduc...</td>\n",
       "      <td>2022-11-02 22:47:00-04:00</td>\n",
       "      <td>[{'name': 'Paul Steinhauser'}]</td>\n",
       "      <td>Former governor and first term Democratic Sen....</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Paul_Steinhauser</td>\n",
       "      <td>1271</td>\n",
       "      <td>62</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biden suggests voting for Republicans is a thr...</td>\n",
       "      <td>President Biden said the only way to repudiate...</td>\n",
       "      <td>https://www.foxnews.com/politics/biden-speech</td>\n",
       "      <td>2022-11-02 22:15:46-04:00</td>\n",
       "      <td>[{'name': 'Haris Alic'}]</td>\n",
       "      <td>President Biden urged Democrats on Wednesday t...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Haris_Alic</td>\n",
       "      <td>478</td>\n",
       "      <td>22</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NYC's Naked Cowboy makes endorsement for gov w...</td>\n",
       "      <td>New York City's Naked Cowboy endorsed Lee Zeld...</td>\n",
       "      <td>https://www.foxnews.com/politics/nyc-naked-cow...</td>\n",
       "      <td>2022-11-02 21:58:25-04:00</td>\n",
       "      <td>[{'name': 'Adam Sabes'}]</td>\n",
       "      <td>The famous Naked Cowboy in New York City's Tim...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Adam_Sabes</td>\n",
       "      <td>205</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wisconsin courts shoot down liberal groups' at...</td>\n",
       "      <td>A Wisconsin appeals court and a circuit judge ...</td>\n",
       "      <td>https://www.foxnews.com/politics/wisconsin-cou...</td>\n",
       "      <td>2022-11-02 21:44:40-04:00</td>\n",
       "      <td>[{'name': 'Bradford Betz'}]</td>\n",
       "      <td>Liberal groups in Wisconsin seeking to change ...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Bradford_Betz</td>\n",
       "      <td>381</td>\n",
       "      <td>20</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Texas gubernatorial candidate Beto O'Rourke jo...</td>\n",
       "      <td>Texas gubernatorial nominee Beto O’Rourke is t...</td>\n",
       "      <td>https://www.foxnews.com/politics/texas-guberna...</td>\n",
       "      <td>2022-11-02 20:38:30-04:00</td>\n",
       "      <td>[{'name': 'Bradford Betz'}]</td>\n",
       "      <td>Texas gubernatorial nominee Beto O’Rourke is a...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>Bradford_Betz</td>\n",
       "      <td>267</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Hassan and Bolduc trade fire in final showdown...   \n",
       "1  Biden suggests voting for Republicans is a thr...   \n",
       "2  NYC's Naked Cowboy makes endorsement for gov w...   \n",
       "3  Wisconsin courts shoot down liberal groups' at...   \n",
       "4  Texas gubernatorial candidate Beto O'Rourke jo...   \n",
       "\n",
       "                                         description  \\\n",
       "0  A bystander took a swing at Republican Senate ...   \n",
       "1  President Biden said the only way to repudiate...   \n",
       "2  New York City's Naked Cowboy endorsed Lee Zeld...   \n",
       "3  A Wisconsin appeals court and a circuit judge ...   \n",
       "4  Texas gubernatorial nominee Beto O’Rourke is t...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.foxnews.com/politics/hassan-bolduc...   \n",
       "1      https://www.foxnews.com/politics/biden-speech   \n",
       "2  https://www.foxnews.com/politics/nyc-naked-cow...   \n",
       "3  https://www.foxnews.com/politics/wisconsin-cou...   \n",
       "4  https://www.foxnews.com/politics/texas-guberna...   \n",
       "\n",
       "         last_published_date                         authors  \\\n",
       "0  2022-11-02 22:47:00-04:00  [{'name': 'Paul Steinhauser'}]   \n",
       "1  2022-11-02 22:15:46-04:00        [{'name': 'Haris Alic'}]   \n",
       "2  2022-11-02 21:58:25-04:00        [{'name': 'Adam Sabes'}]   \n",
       "3  2022-11-02 21:44:40-04:00     [{'name': 'Bradford Betz'}]   \n",
       "4  2022-11-02 20:38:30-04:00     [{'name': 'Bradford Betz'}]   \n",
       "\n",
       "                                                text  published_day  \\\n",
       "0  Former governor and first term Democratic Sen....              2   \n",
       "1  President Biden urged Democrats on Wednesday t...              2   \n",
       "2  The famous Naked Cowboy in New York City's Tim...              2   \n",
       "3  Liberal groups in Wisconsin seeking to change ...              2   \n",
       "4  Texas gubernatorial nominee Beto O’Rourke is a...              2   \n",
       "\n",
       "   published_month  num_authors            author  word_count  line_count  \\\n",
       "0               11            1  Paul_Steinhauser        1271          62   \n",
       "1               11            1        Haris_Alic         478          22   \n",
       "2               11            1        Adam_Sabes         205          18   \n",
       "3               11            1     Bradford_Betz         381          20   \n",
       "4               11            1     Bradford_Betz         267          15   \n",
       "\n",
       "     neg    neu    pos  compound  \n",
       "0  0.268  0.732  0.000   -0.6705  \n",
       "1  0.298  0.702  0.000   -0.5267  \n",
       "2  0.000  0.757  0.243    0.5423  \n",
       "3  0.290  0.710  0.000   -0.5423  \n",
       "4  0.000  1.000  0.000    0.0000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat([data, results_df], axis=1)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Former President Trump celebrates 'ALL' endorsement wins in primary: 'Great candidates!'\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.loc[combined_df[\"pos\"].idxmax(), \"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published_day</th>\n",
       "      <th>published_month</th>\n",
       "      <th>num_authors</th>\n",
       "      <th>word_count</th>\n",
       "      <th>line_count</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3972.000000</td>\n",
       "      <td>3972.000000</td>\n",
       "      <td>3972.000000</td>\n",
       "      <td>3972.000000</td>\n",
       "      <td>3972.000000</td>\n",
       "      <td>3972.000000</td>\n",
       "      <td>3972.000000</td>\n",
       "      <td>3972.000000</td>\n",
       "      <td>3972.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.787513</td>\n",
       "      <td>8.453424</td>\n",
       "      <td>1.119084</td>\n",
       "      <td>610.804884</td>\n",
       "      <td>31.652064</td>\n",
       "      <td>0.109221</td>\n",
       "      <td>0.812165</td>\n",
       "      <td>0.078617</td>\n",
       "      <td>-0.065043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.934083</td>\n",
       "      <td>1.335676</td>\n",
       "      <td>0.447909</td>\n",
       "      <td>340.785100</td>\n",
       "      <td>19.232276</td>\n",
       "      <td>0.136235</td>\n",
       "      <td>0.158318</td>\n",
       "      <td>0.110806</td>\n",
       "      <td>0.394567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.966100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.701000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.361200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.823000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>734.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.194000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.177900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9672.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>0.837000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.936000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       published_day  published_month  num_authors   word_count   line_count  \\\n",
       "count    3972.000000      3972.000000  3972.000000  3972.000000  3972.000000   \n",
       "mean       16.787513         8.453424     1.119084   610.804884    31.652064   \n",
       "std         8.934083         1.335676     0.447909   340.785100    19.232276   \n",
       "min         1.000000         6.000000     0.000000    31.000000     3.000000   \n",
       "25%         9.000000         7.000000     1.000000   399.000000    21.000000   \n",
       "50%        18.000000         8.000000     1.000000   534.000000    28.000000   \n",
       "75%        25.000000        10.000000     1.000000   734.000000    37.000000   \n",
       "max        31.000000        11.000000     5.000000  9672.000000   647.000000   \n",
       "\n",
       "               neg          neu          pos     compound  \n",
       "count  3972.000000  3972.000000  3972.000000  3972.000000  \n",
       "mean      0.109221     0.812165     0.078617    -0.065043  \n",
       "std       0.136235     0.158318     0.110806     0.394567  \n",
       "min       0.000000     0.163000     0.000000    -0.966100  \n",
       "25%       0.000000     0.701000     0.000000    -0.361200  \n",
       "50%       0.000000     0.823000     0.000000     0.000000  \n",
       "75%       0.194000     1.000000     0.155000     0.177900  \n",
       "max       0.837000     1.000000     0.668000     0.936000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "## pulling a specific model pretrained on sentiment analysis\n",
    "task='sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "# config = AutoConfig.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying Modeling Long Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data[\"text\"][1]\n",
    "tokens = tokenizer.encode_plus(text, add_special_tokens=False, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 6517, 15478,  2966,  1574,    15,   307,     7,   311,    62,    23,\n",
       "             5,  4583,   148,   220,   186,    18, 12076,  1727,    50,    22,\n",
       "         25487,     5,  2933,  1572,    14, 32351,    13,   476,   113,     7,\n",
       "          6638,   409,    23,   470,  4593,     4,   947,   282, 39596,   131,\n",
       "         15478,  2966,    10,  2180,     9,  2732,    23,    10,  1557,   496,\n",
       "          1674,   515,  1025,  1332,  5088,    11,   663,     6,   211,     4,\n",
       "           347,     4,    45,     7,   185,     5,   729,    13,  4159,     4,\n",
       "            20,   394,  3811,    14,  1574,    56,     7,   311,    62,    23,\n",
       "             5,  4583,   142,  1858,   115,    45,    28, 29168,    19,   559,\n",
       "           476,     4,   359,   282, 39596,   131,    22,   170,   214,  2114,\n",
       "            10, 17032,  1151,    60,    26, 15478,     4,    22,   170,   531,\n",
       "            19,    65,  8642,     6, 16681,  2236,  1994,     6,    25,    10,\n",
       "           247,     8,   224,    89,    18,   117,   317,    13,  6679, 18438,\n",
       "            50,   559,  1476,    11,   730,    72,   947,   282, 39596,   131,\n",
       "          1590,    39,  4166,     6, 15478, 27627,  4008,    15,   375,  8770,\n",
       "          7674,     5,  1084, 22091,    25,    41,   945,     7,  5898,  5865,\n",
       "             5,  3932,    18,   559, 18549,     4,   947,   282, 39596,   131,\n",
       "           256,  3376,  2747,  3732,   975, 10962, 31864,   163,  2688,  2796,\n",
       "          5089,   128, 35437,  2688,  1862,  1941,   234,  6034,   108,    83,\n",
       "         36696,  3243,  6178,   717, 32958,  6015,  3603,  3063,  1862, 29505,\n",
       "           250,  4979, 16821, 43743,  6557,  1437,    22,   243,    18,  2319,\n",
       "            14,    55,    87,  2993,   646, 43070,   742,   729,  3069,  4733,\n",
       "            32,    15,     5,  5250,    70,   420,   730,    42,    76,    60,\n",
       "            26, 15478,     4,    22,   713,    16,    45,    59,   162,  1555,\n",
       "            85,    18,    59,     5, 28327,     9,    84,  4593,    72,   947,\n",
       "           282, 39596,   131, 15478,    18,  1450,   283,   540,    87,    10,\n",
       "           186,    71,   446,  6358,  8239,  9560,    18,  1623,    21, 26435,\n",
       "          4487,    11,   764,  2659,     6,   886,     4,   616,     5, 12704,\n",
       "            13,     5,  2080,  1189,  9684,     6,  1574,    33,    57,  2119,\n",
       "             7,  2026,    14,   107,     9,  3932,  3633,   156,  9560,     8,\n",
       "            69,   284,  3247,     4,   947,   282, 39596,   131,   163,  2688,\n",
       "          2796,    17,    27,   104, 29505,   250,    12,   387, 13246,  1862,\n",
       "          3703,   255,  2492, 19990, 21097, 23981,   500, 11595, 35923,  4979,\n",
       "         16821, 43743,  6557,    22,   713,  1476,   136,  1574,     6,  1858,\n",
       "             6,     8, 25167,   503,    95,   608,    49,  1315,    32,     5,\n",
       "         15180,     9,  5738,   174,    13,   476,     8,  1963,    60,    26,\n",
       "         15478,     4,    22,   574,   918,  6636,    81,     8,    81,     7,\n",
       "          5368,    10,  4943,     9,  6378,     6,  4157,     6, 37417,  1168,\n",
       "             6,     8,   190,  1476,     4,    22, 12845,  4583,   311,  1983,\n",
       "             6,   959,     6,    32,    45,  2159,     5,  8770,  2876,   843,\n",
       "            12,   180,   239,  2680,     4,   616, 15478,    18,  2846,   691,\n",
       "            34,  5898,  9968,    11,   485,   688,     6,    10,  2063,   491,\n",
       "          2902,    42,   353,   303,    14,  1858,   483,  1574,   566,   533,\n",
       "          1983,    15,     5,  5744, 12832,  5250,     4,   947,   282, 39596,\n",
       "           131,  1437,    20,   276,  2902,   303,    14,  8572,   207,     9,\n",
       "          1983,    26,    51,    58,  2778,  2273,    59,  2680,     8,   723,\n",
       "           850,     6,   150,   129,  6657,   207,    26,     5,   276,    59,\n",
       "             5,  1226,    18, 16747,   559,  9696,     4,    22, 18393, 15478,\n",
       "          3604,  8618,    53,    34,  1386, 12959,  1538,     8,  5278, 24845,\n",
       "          1791,     6,   150,   442,   301,    55,  3214,    13,    70,    60,\n",
       "            26,   248, 19864, 11896,  1509, 18322,     6,     5,  3428,  7760,\n",
       "             9,     5,  1172,   496,  1674,     4,    22,  5771,  1858,  1091,\n",
       "          2061,    15,     5,   743,    14,   948,   144,     7,  1983,     6,\n",
       "         15478,     8,  1574,    32,  2342,  8459,    11,     5,   507,   360,\n",
       "           142,    51,    33,   685,  2842,    19,     5,  1379,     9,  1232,\n",
       "          3306,     7,   120,    30,    72,  1437,   993,  1858,    58,    67,\n",
       "          2119,     7, 29508, 15478,    18,  1450,     6,   584,     5,   394,\n",
       "            21,  6475,     7,  2501,     5,  7169,  5108,     9,  1574,   149,\n",
       "          2490,    12, 27669,  2961,     4,   359,   282, 39596,   131, 15041,\n",
       "          3842,  7777,  1941,  7481,  7857, 30235,    22,  6517, 15478,    16,\n",
       "           667,     7, 11079,     8, 29188,    23,    10,    86,    77,   730,\n",
       "           782,     7, 17013,   578, 13437,    37,    64,    17,    27,    90,\n",
       "          1067,    59,    39,  1986,    14,    33,  3185,    62,     5,   701,\n",
       "             9,  1207,    60,    26,   446, 15539,  5337,  2363,  9469,     6,\n",
       "           248,    12, 25839,     4,   947,   282, 39596,   131]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tokens['input_ids'][0]))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "# define target chunksize\n",
    "chunksize = 512\n",
    "\n",
    "# split into chunks of 510 tokens, we also convert to list (default is tuple which is immutable)\n",
    "input_id_chunks = list(tokens['input_ids'][0].split(chunksize - 2))\n",
    "mask_chunks = list(tokens['attention_mask'][0].split(chunksize - 2))\n",
    "\n",
    "\n",
    "# loop through each chunk\n",
    "for i in range(len(input_id_chunks)):\n",
    "    # add CLS and SEP tokens to input IDs\n",
    "    input_id_chunks[i] = torch.cat([\n",
    "        torch.tensor([101]), input_id_chunks[i], torch.tensor([102])\n",
    "    ])\n",
    "    # add attention tokens to attention mask\n",
    "    mask_chunks[i] = torch.cat([\n",
    "        torch.tensor([1]), mask_chunks[i], torch.tensor([1])\n",
    "    ])\n",
    "    # get required padding length\n",
    "    pad_len = chunksize - input_id_chunks[i].shape[0]\n",
    "    # check if tensor length satisfies required chunk size\n",
    "    if pad_len > 0:\n",
    "        # if padding length is more than 0, we must add padding\n",
    "        input_id_chunks[i] = torch.cat([\n",
    "            input_id_chunks[i], torch.Tensor([0] * pad_len)\n",
    "        ])\n",
    "        mask_chunks[i] = torch.cat([\n",
    "            mask_chunks[i], torch.Tensor([0] * pad_len)\n",
    "        ])\n",
    "\n",
    "# check length of each tensor\n",
    "for chunk in input_id_chunks:\n",
    "    print(len(chunk))\n",
    "# print final chunk so we can see 101, 102, and 0 (PAD) tokens are all correctly placed\n",
    "# chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0100e+02, 9.0000e+00, 5.0000e+00, 1.1720e+03, 4.9600e+02, 1.6740e+03,\n",
       "        4.0000e+00, 2.2000e+01, 5.7710e+03, 1.8580e+03, 1.0910e+03, 2.0610e+03,\n",
       "        1.5000e+01, 5.0000e+00, 7.4300e+02, 1.4000e+01, 9.4800e+02, 1.4400e+02,\n",
       "        7.0000e+00, 1.9830e+03, 6.0000e+00, 1.5478e+04, 8.0000e+00, 1.5740e+03,\n",
       "        3.2000e+01, 2.3420e+03, 8.4590e+03, 1.1000e+01, 5.0000e+00, 5.0700e+02,\n",
       "        3.6000e+02, 1.4200e+02, 5.1000e+01, 3.3000e+01, 6.8500e+02, 2.8420e+03,\n",
       "        1.9000e+01, 5.0000e+00, 1.3790e+03, 9.0000e+00, 1.2320e+03, 3.3060e+03,\n",
       "        7.0000e+00, 1.2000e+02, 3.0000e+01, 7.2000e+01, 1.4370e+03, 9.9300e+02,\n",
       "        1.8580e+03, 5.8000e+01, 6.7000e+01, 2.1190e+03, 7.0000e+00, 2.9508e+04,\n",
       "        1.5478e+04, 1.8000e+01, 1.4500e+03, 6.0000e+00, 5.8400e+02, 5.0000e+00,\n",
       "        3.9400e+02, 2.1000e+01, 6.4750e+03, 7.0000e+00, 2.5010e+03, 5.0000e+00,\n",
       "        7.1690e+03, 5.1080e+03, 9.0000e+00, 1.5740e+03, 1.4900e+02, 2.4900e+03,\n",
       "        1.2000e+01, 2.7669e+04, 2.9610e+03, 4.0000e+00, 3.5900e+02, 2.8200e+02,\n",
       "        3.9596e+04, 1.3100e+02, 1.5041e+04, 3.8420e+03, 7.7770e+03, 1.9410e+03,\n",
       "        7.4810e+03, 7.8570e+03, 3.0235e+04, 2.2000e+01, 6.5170e+03, 1.5478e+04,\n",
       "        1.6000e+01, 6.6700e+02, 7.0000e+00, 1.1079e+04, 8.0000e+00, 2.9188e+04,\n",
       "        2.3000e+01, 1.0000e+01, 8.6000e+01, 7.7000e+01, 7.3000e+02, 7.8200e+02,\n",
       "        7.0000e+00, 1.7013e+04, 5.7800e+02, 1.3437e+04, 3.7000e+01, 6.4000e+01,\n",
       "        1.7000e+01, 2.7000e+01, 9.0000e+01, 1.0670e+03, 5.9000e+01, 3.9000e+01,\n",
       "        1.9860e+03, 1.4000e+01, 3.3000e+01, 3.1850e+03, 6.2000e+01, 5.0000e+00,\n",
       "        7.0100e+02, 9.0000e+00, 1.2070e+03, 6.0000e+01, 2.6000e+01, 4.4600e+02,\n",
       "        1.5539e+04, 5.3370e+03, 2.3630e+03, 9.4690e+03, 6.0000e+00, 2.4800e+02,\n",
       "        1.2000e+01, 2.5839e+04, 4.0000e+00, 9.4700e+02, 2.8200e+02, 3.9596e+04,\n",
       "        1.3100e+02, 1.0200e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  6517, 15478,  ...,  3428,  7760,   102],\n",
       "         [  101,     9,     5,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_ids = torch.stack(input_id_chunks)\n",
    "attention_mask = torch.stack(mask_chunks)\n",
    "\n",
    "input_dict = {\n",
    "    'input_ids': input_ids.long(),\n",
    "    'attention_mask': attention_mask.int()\n",
    "}\n",
    "input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3930, 0.5565, 0.0505], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "outputs = model(**input_dict)\n",
    "probs = torch.nn.functional.softmax(outputs[0], dim=-1)\n",
    "probs = probs.mean(dim=0)\n",
    "probs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End Trying Modeling Long Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biden suggests voting for Republicans is a threat to democracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'neg': 0.298, 'neu': 0.702, 'pos': 0.0, 'compound': -0.5267}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data[\"title\"][1])\n",
    "sia.polarity_scores(data[\"title\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roberta_neg': 0.66241485,\n",
       " 'roberta_neu': 0.3247515,\n",
       " 'roberta_pos': 0.012833751}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## running on roberta model\n",
    "def get_roberta_sentiment(text):\n",
    "    encoded_text = tokenizer(text, return_tensors=\"pt\")\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    ## scores are in order of negative, neutral and positive\n",
    "    scores_dict = {\"roberta_neg\":scores[0], \"roberta_neu\":scores[1], \"roberta_pos\":scores[2]}\n",
    "    return scores_dict\n",
    "\n",
    "\n",
    "scores = get_roberta_sentiment(data[\"title\"][1])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3972/3972 [03:06<00:00, 21.30it/s]\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for idx, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    try:\n",
    "        text = row[\"title\"]\n",
    "        id = idx\n",
    "        vader_results = sia.polarity_scores(text)\n",
    "        vader_results_rename = {}\n",
    "        for k,v in vader_results.items():\n",
    "            vader_results_rename[f\"vader_{k}\"] = v\n",
    "        roberta_results = get_roberta_sentiment(text)\n",
    "        both = {**vader_results_rename, **roberta_results}\n",
    "        results[idx] = both\n",
    "    except RuntimeError:\n",
    "        print(f\"Broke for id {idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>roberta_neg</th>\n",
       "      <th>roberta_neu</th>\n",
       "      <th>roberta_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.268</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6705</td>\n",
       "      <td>0.214919</td>\n",
       "      <td>0.765167</td>\n",
       "      <td>0.019915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.298</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5267</td>\n",
       "      <td>0.662415</td>\n",
       "      <td>0.324751</td>\n",
       "      <td>0.012834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.005948</td>\n",
       "      <td>0.538470</td>\n",
       "      <td>0.455582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.290</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>0.346270</td>\n",
       "      <td>0.637059</td>\n",
       "      <td>0.016671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.056946</td>\n",
       "      <td>0.885563</td>\n",
       "      <td>0.057491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3967</th>\n",
       "      <td>0.152</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.224884</td>\n",
       "      <td>0.703206</td>\n",
       "      <td>0.071910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3968</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.570033</td>\n",
       "      <td>0.403358</td>\n",
       "      <td>0.026609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3969</th>\n",
       "      <td>0.080</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.502582</td>\n",
       "      <td>0.481971</td>\n",
       "      <td>0.015446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>0.173</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>0.048049</td>\n",
       "      <td>0.920026</td>\n",
       "      <td>0.031925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.006440</td>\n",
       "      <td>0.189757</td>\n",
       "      <td>0.803802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3972 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      vader_neg  vader_neu  vader_pos  vader_compound  roberta_neg  \\\n",
       "0         0.268      0.732      0.000         -0.6705     0.214919   \n",
       "1         0.298      0.702      0.000         -0.5267     0.662415   \n",
       "2         0.000      0.757      0.243          0.5423     0.005948   \n",
       "3         0.290      0.710      0.000         -0.5423     0.346270   \n",
       "4         0.000      1.000      0.000          0.0000     0.056946   \n",
       "...         ...        ...        ...             ...          ...   \n",
       "3967      0.152      0.691      0.157          0.0258     0.224884   \n",
       "3968      0.000      1.000      0.000          0.0000     0.570033   \n",
       "3969      0.080      0.747      0.172          0.3818     0.502582   \n",
       "3970      0.173      0.827      0.000         -0.3182     0.048049   \n",
       "3971      0.000      0.763      0.237          0.4767     0.006440   \n",
       "\n",
       "      roberta_neu  roberta_pos  \n",
       "0        0.765167     0.019915  \n",
       "1        0.324751     0.012834  \n",
       "2        0.538470     0.455582  \n",
       "3        0.637059     0.016671  \n",
       "4        0.885563     0.057491  \n",
       "...           ...          ...  \n",
       "3967     0.703206     0.071910  \n",
       "3968     0.403358     0.026609  \n",
       "3969     0.481971     0.015446  \n",
       "3970     0.920026     0.031925  \n",
       "3971     0.189757     0.803802  \n",
       "\n",
       "[3972 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([data, results_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Crist praises Biden, says president is 'phenomenal' and he 'can't wait' to have his support in Florida\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.loc[final_df[\"roberta_pos\"].idxmax(), \"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Former President Trump celebrates 'ALL' endorsement wins in primary: 'Great candidates!'\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.loc[final_df[\"vader_pos\"].idxmax(), \"title\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the `roBerta` model throws an error when the input text is too long.  I wonder if can breakdown the article into multiple lines, run thru the model and then take some kind of average for the sentiment analysis. Would that make sense? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = data.sample(1)[\"text\"].values[0]\n",
    "\n",
    "# get_roberta_sentiment(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_sentiments = [get_roberta_sentiment(sent) for sent in sentences]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "roberta_neg    0.099001\n",
       "roberta_neu    0.771131\n",
       "roberta_pos    0.129868\n",
       "dtype: float32"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_sentiments_df = pd.DataFrame(sent_sentiments)\n",
    "sent_sentiments_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3972/3972 [1:39:18<00:00,  1.50s/it]\n"
     ]
    }
   ],
   "source": [
    "text_results = {}\n",
    "for idx, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    try:\n",
    "        text = row[\"text\"]\n",
    "        id = idx\n",
    "        vader_results = sia.polarity_scores(text)\n",
    "        vader_results_rename = {}\n",
    "        for k,v in vader_results.items():\n",
    "            vader_results_rename[f\"vader_{k}\"] = v\n",
    "        sentences = sent_tokenize(test_text)    \n",
    "        sent_sentiments = [get_roberta_sentiment(sent) for sent in sentences]\n",
    "        neg = [sent[\"roberta_neg\"] for sent in sent_sentiments]\n",
    "        pos = [sent[\"roberta_pos\"] for sent in sent_sentiments]\n",
    "        neu = [sent[\"roberta_neu\"] for sent in sent_sentiments]\n",
    "        roberta_results = {\"roberta_neg\":np.mean(neg), \"roberta_pos\":np.mean(pos), \"roberta_neu\":np.mean(neu)}\n",
    "        both = {**vader_results_rename, **roberta_results}\n",
    "        results[idx] = both\n",
    "    except RuntimeError:\n",
    "        print(f\"Broke for id {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_sentiments\n",
    "neg = [sent[\"roberta_neg\"] for sent in sent_sentiments]\n",
    "pos = [sent[\"roberta_pos\"] for sent in sent_sentiments]\n",
    "neu = [sent[\"roberta_neu\"] for sent in sent_sentiments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roberta_neg': 0.09900135,\n",
       " 'roberta_pos': 0.1298681,\n",
       " 'roberta_neu': 0.77113056}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77113056"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18134831,\n",
       " 0.063188896,\n",
       " 0.023074752,\n",
       " 0.03626485,\n",
       " 0.12284745,\n",
       " 0.05646329,\n",
       " 0.02577409,\n",
       " 0.10676716,\n",
       " 0.042654786,\n",
       " 0.10904879,\n",
       " 0.012940776,\n",
       " 0.121790655,\n",
       " 0.09689276,\n",
       " 0.8645746,\n",
       " 0.42098108,\n",
       " 0.02996848,\n",
       " 0.026538102,\n",
       " 0.05098097,\n",
       " 0.021859746,\n",
       " 0.18340261]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>roberta_neg</th>\n",
       "      <th>roberta_pos</th>\n",
       "      <th>roberta_neu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.105</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.9869</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.088</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.9520</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.087</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.7897</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.9544</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.068</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.078</td>\n",
       "      <td>-0.0152</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3967</th>\n",
       "      <td>0.047</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3968</th>\n",
       "      <td>0.113</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.9981</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3969</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>0.058</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.8732</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3972 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      vader_neg  vader_neu  vader_pos  vader_compound  roberta_neg  \\\n",
       "0         0.105      0.812      0.083         -0.9869     0.099001   \n",
       "1         0.088      0.865      0.046         -0.9520     0.099001   \n",
       "2         0.087      0.849      0.064         -0.7897     0.099001   \n",
       "3         0.075      0.899      0.026         -0.9544     0.099001   \n",
       "4         0.068      0.853      0.078         -0.0152     0.099001   \n",
       "...         ...        ...        ...             ...          ...   \n",
       "3967      0.047      0.848      0.105          0.9983     0.099001   \n",
       "3968      0.113      0.842      0.044         -0.9981     0.099001   \n",
       "3969      0.024      0.800      0.176          0.9989     0.099001   \n",
       "3970      0.058      0.899      0.044         -0.8732     0.099001   \n",
       "3971      0.040      0.850      0.111          0.9925     0.099001   \n",
       "\n",
       "      roberta_pos  roberta_neu  \n",
       "0        0.129868     0.771131  \n",
       "1        0.129868     0.771131  \n",
       "2        0.129868     0.771131  \n",
       "3        0.129868     0.771131  \n",
       "4        0.129868     0.771131  \n",
       "...           ...          ...  \n",
       "3967     0.129868     0.771131  \n",
       "3968     0.129868     0.771131  \n",
       "3969     0.129868     0.771131  \n",
       "3970     0.129868     0.771131  \n",
       "3971     0.129868     0.771131  \n",
       "\n",
       "[3972 rows x 7 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>roberta_neg</th>\n",
       "      <th>roberta_pos</th>\n",
       "      <th>roberta_neu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.105</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.083</td>\n",
       "      <td>-0.9869</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.088</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.9520</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.087</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.7897</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.9544</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.068</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.078</td>\n",
       "      <td>-0.0152</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3967</th>\n",
       "      <td>0.047</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.9983</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3968</th>\n",
       "      <td>0.113</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.9981</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3969</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>0.058</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.8732</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.129868</td>\n",
       "      <td>0.771131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3972 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      vader_neg  vader_neu  vader_pos  vader_compound  roberta_neg  \\\n",
       "0         0.105      0.812      0.083         -0.9869     0.099001   \n",
       "1         0.088      0.865      0.046         -0.9520     0.099001   \n",
       "2         0.087      0.849      0.064         -0.7897     0.099001   \n",
       "3         0.075      0.899      0.026         -0.9544     0.099001   \n",
       "4         0.068      0.853      0.078         -0.0152     0.099001   \n",
       "...         ...        ...        ...             ...          ...   \n",
       "3967      0.047      0.848      0.105          0.9983     0.099001   \n",
       "3968      0.113      0.842      0.044         -0.9981     0.099001   \n",
       "3969      0.024      0.800      0.176          0.9989     0.099001   \n",
       "3970      0.058      0.899      0.044         -0.8732     0.099001   \n",
       "3971      0.040      0.850      0.111          0.9925     0.099001   \n",
       "\n",
       "      roberta_pos  roberta_neu  \n",
       "0        0.129868     0.771131  \n",
       "1        0.129868     0.771131  \n",
       "2        0.129868     0.771131  \n",
       "3        0.129868     0.771131  \n",
       "4        0.129868     0.771131  \n",
       "...           ...          ...  \n",
       "3967     0.129868     0.771131  \n",
       "3968     0.129868     0.771131  \n",
       "3969     0.129868     0.771131  \n",
       "3970     0.129868     0.771131  \n",
       "3971     0.129868     0.771131  \n",
       "\n",
       "[3972 rows x 7 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.query(\"roberta_neu == 0.77113056\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "914eef65da1375b54976b1eb4c0a6192cf68c9b736369c9231d1c03e2f3fef86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
